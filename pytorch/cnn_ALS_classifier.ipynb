{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "# pip install torch==1.0.0 torchvision==0.2.1 -f https://download.pytorch.org/whl/cu80/torch_stable.html\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu80\n",
    "# https://download.pytorch.org/whl/cu80/torch-1.0.0-cp35-cp35m-win_amd64.whl\n",
    "# pip install torch -f https://download.pytorch.org/whl/cu80/torch-1.0.0-cp35-cp35m-win_amd64.whl\n",
    "# pip install torch -f /d/3.Install/torch-1.0.0-cp37-cp37m-win_amd64.whl (success)\n",
    "# pip install torch==1.11.0\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "# pip install torchsummary\n",
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# torch.version.cuda\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "file = open(\"config.json\")\n",
    "config = json.load(file)\n",
    "# print(config.keys())\n",
    "print(config['data']['frame_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 44100              # Hz, sampling frequency\n",
    "f_size = config['data']['frame_size']\n",
    "h_size = config['data']['hop_size']\n",
    "n_mel_channels = config['data']['n_mel_channels']\n",
    "\n",
    "supra_frame_duration = 0.5  # seconds\n",
    "supra_frame_length = round(supra_frame_duration / (h_size/fs)) # need to read from config.json / \n",
    "\n",
    "dir_HC = '../wav'+ os.sep + 'HC' + os.sep\n",
    "dir_ALS = '../wav' + os.sep + 'ALS' + os.sep\n",
    "directory_ALS = os.listdir(dir_ALS)\n",
    "directory_HC = os.listdir(dir_HC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-analysis (transform wav-file to mel-spectrogramms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((20000,n_mel_channels, supra_frame_length))   # data\n",
    "y = np.zeros((20000,1))                     # labels\n",
    "X_global_index = 0\n",
    "X_ids = list([])\n",
    "# Cycle for HC (helthy controls)\n",
    "for i in range(len(directory_HC)):    \n",
    "    if directory_HC[i][-5:]=='a.wav':\n",
    "        # print(directory_HC[i][-5:])\n",
    "        fileName = dir_HC + directory_HC[i]\n",
    "        x, sr = librosa.load(fileName, sr=None, mono=True, offset=0.0, duration=None)\n",
    "\n",
    "        X_melspec = librosa.feature.melspectrogram(y=x, sr=sr, n_mels=64, n_fft=f_size, hop_length=h_size, window='hann', center=False, power=1.0)\n",
    "        X_melspec = 20*np.log10(X_melspec)\n",
    "            \n",
    "        frame_num = X_melspec.shape[1]    \n",
    "\n",
    "        X_melspec = X_melspec.astype(np.half)\n",
    "        X_melspec.tofile(dir_HC + directory_HC[i][:-4] +'_mel.dat')\n",
    "\n",
    "# #       #Запись фрагметов спектра в трехмерный массив \n",
    "#         N_supra_frames = frame_num - supra_frame_length + 1\n",
    "\n",
    "#         # generator comprehension\n",
    "#         gen_range = (n * 2 for n in range(0, np.floor(N_supra_frames/2).astype(int)))\n",
    "#         for n in gen_range:\n",
    "#             X[X_global_index,:,:] = X_melspec[:,n:n+supra_frame_length]\n",
    "#             X_ids.append(int(directory_HC[i][0:3]))\n",
    "#             y[X_global_index] = 0\n",
    "#             X_global_index = X_global_index +1\n",
    "    \n",
    "# Cycle for ALS (pathology)\n",
    "for i in range(len(directory_ALS)):\n",
    "    if directory_ALS[i][-5:]=='a.wav':\n",
    "        fileName = dir_ALS + directory_ALS[i]\n",
    "        x, sr = librosa.load(fileName, sr=None, mono=True, offset=0.0, duration=None)\n",
    "\n",
    "        X_melspec = librosa.feature.melspectrogram(y=x, sr=sr, n_mels=64, n_fft=f_size, hop_length=h_size, window='hann', center=False, power=1.0)\n",
    "        X_melspec = 20*np.log10(X_melspec)\n",
    "            \n",
    "        frame_num = X_melspec.shape[1]\n",
    "     \n",
    "        X_melspec = X_melspec.astype(np.half)\n",
    "        X_melspec.tofile(dir_ALS + directory_ALS[i][:-4] +'_mel.dat')\n",
    "\n",
    "# #       #Запись фрагметов спектра в трехмерный массив \n",
    "#         N_supra_frames = frame_num - supra_frame_length + 1\n",
    "\n",
    "#         # generator comprehension\n",
    "#         gen_range = (n * 2 for n in range(0, np.floor(N_supra_frames/2).astype(int)))\n",
    "#         for n in gen_range:\n",
    "#             X[X_global_index,:,:] = X_melspec[:,n:n+supra_frame_length]\n",
    "#             X_ids.append(int(directory_ALS[i][0:3]))\n",
    "#             y[X_global_index] = 1\n",
    "#             X_global_index = X_global_index + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALSDataset(Dataset):\n",
    "    def __init__(self, dir_HC_path, dir_ALS_path):\n",
    "        \"\"\"\n",
    "        Аргументы:\n",
    "            dir_HC_path -- путь к папке с записями здоровых голосов\n",
    "            dir_ALS_path -- путь к папке с записями голосов пациентов с БАС\n",
    "        \"\"\"\n",
    "        # self.dir_HC_path = []\n",
    "        # self.dir_ALS_path = []\n",
    "        self._ids = list([])    # speaker IDs\n",
    "        # 5-fold CV: 13+13+13+13+12\n",
    "        # ALS: 8,20,21, 22, 24, 25,27,28,31,32,39, 42,46,48,52,55,58,62,64,68,72,76,78,80,84,92,94,96,98,100,102\n",
    "        # HC : 131, 129, 127, 125, 123, 121, 119, 117, 115, 113, 111, 109, 107, 99, 97, 89, 86, 85, 81, 77, 65, 63, 61, 53, 49, 42, 28, 26, 24, 16, 6, 4, 2 \n",
    "        \n",
    "                                                                                        # HC men+women / ALS men+women\n",
    "        self.folds = list(([26,   97, 117,  85,  53,  86, 127,  92, 102,  27,  32,  72,  39], # 3+4 HC / 3+3 ALS\n",
    "                           [28,  123,  63,  99,  81, 125, 129,  68,  21,  55,  48,  78,  42], # 3+4 HC / 4+2 ALS\n",
    "                           [61,   16, 115, 109, 111,   2, 107,  46,  84,  64,  52,  24,  76], # 2+5 HC / 4+2 ALS\n",
    "                           [77,    6,  65,  24, 131, 119,  25,  94,  62,  28,   8,  98,  22], # 3+3 HC / 5+2 ALS\n",
    "                           [49,   89,   4,  42, 113, 121,  96,  20,  58,  80,  31, 100]))     # 2+4 HC / 4+2 ALS\n",
    "        \n",
    "        self.folds_val = list(([49, 42, 20, 31],\n",
    "                              [97, 53,  92, 32],\n",
    "                              [28, 99, 129, 55],  \n",
    "                              [61, 111, 84, 76],  \n",
    "                              [77, 24, 94, 8]))\n",
    "                              \n",
    "        f_size = 512            # need to read from config.json\n",
    "        h_size = 256            # need to read from config.json\n",
    "        n_mel_channels = 64     # need to read from config.json\n",
    "        supra_frame_length = 86 # need to read from config.json\n",
    "        self.X = np.zeros((20000, n_mel_channels, supra_frame_length))   # data\n",
    "        self.y = np.zeros((20000,1))                         # labels\n",
    "        X_global_index = 0\n",
    "        self.X_ids = list([])\n",
    "\n",
    "        # Cycle for HC (helthy controls)        \n",
    "        directory_HC = os.listdir(dir_HC_path)       \n",
    "        for i in range(len(directory_HC)):\n",
    "            if directory_HC[i][-9:]=='a_mel.dat':\n",
    "                fileName = dir_HC + directory_HC[i]\n",
    "            \n",
    "                X_spec = np.fromfile(dir_HC + directory_HC[i], dtype=np.half)\n",
    "                X_spec = np.reshape(X_spec,(n_mel_channels, np.floor(len(X_spec)/n_mel_channels).astype(int)))        \n",
    "\n",
    "                #Запись фрагметов спектра в трехмерный массив \n",
    "                frame_num = X_spec.shape[1]\n",
    "                N_supra_frames = frame_num - supra_frame_length + 1\n",
    "\n",
    "                # generator comprehension\n",
    "                gen_range = (n * 2 for n in range(0, np.floor(N_supra_frames/2).astype(int)))\n",
    "                for n in gen_range:\n",
    "                    self.X[X_global_index,:,:] = X_spec[:,n:n+supra_frame_length]\n",
    "                    self.X_ids.append(int(directory_HC[i][0:3]))\n",
    "                    self.y[X_global_index] = 0\n",
    "                    X_global_index = X_global_index +1\n",
    "\n",
    "        # Cycle for ALS (pathology)\n",
    "        directory_ALS = os.listdir(dir_ALS_path)       \n",
    "        for i in range(len(directory_ALS)):\n",
    "            if directory_ALS[i][-9:]=='a_mel.dat':\n",
    "                fileName = dir_ALS + directory_ALS[i]        \n",
    "\n",
    "                # print(fileName)\n",
    "\n",
    "                X_spec = np.fromfile(dir_ALS + directory_ALS[i], dtype=np.half)\n",
    "                X_spec = np.reshape(X_spec,(n_mel_channels, np.floor(len(X_spec)/n_mel_channels).astype(int)))\n",
    "\n",
    "        #       #Запись фрагметов спектра в трехмерный массив\n",
    "                frame_num = X_spec.shape[1]\n",
    "                N_supra_frames = frame_num - supra_frame_length + 1\n",
    "\n",
    "                # generator comprehension\n",
    "                gen_range = (n * 2 for n in range(0, np.floor(N_supra_frames/2).astype(int)))\n",
    "                for n in gen_range:\n",
    "                    self.X[X_global_index,:,:] = X_spec[:,n:n+supra_frame_length]\n",
    "                    self.X_ids.append(int(directory_ALS[i][0:3]))\n",
    "                    self.y[X_global_index] = 1\n",
    "                    X_global_index = X_global_index + 1\n",
    "            \n",
    "        inds_to_delete = np.array(range(self.y.shape[0]))>=X_global_index\n",
    "        self.y = np.delete(self.y,inds_to_delete)\n",
    "        self.X = np.delete(self.X,inds_to_delete, axis=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index,:,:], self.y[index]\n",
    "\n",
    "    def get_kth_fold_inds(self, fold_num):\n",
    "        ids_train = list([])\n",
    "        ids_val  = list([])\n",
    "        ids_test = list([])\n",
    "        for i in range(len(self.X_ids)):\n",
    "            if self.X_ids[i] in self.folds[fold_num]:\n",
    "                ids_test.append(i)\n",
    "            elif self.X_ids[i] in self.folds_val[fold_num]:\n",
    "                ids_val.append(i)\n",
    "            else:\n",
    "                ids_train.append(i)\n",
    "        return (ids_train,ids_val, ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_HC = '../wav'+ os.sep + 'HC' + os.sep\n",
    "dir_ALS = '../wav' + os.sep + 'ALS' + os.sep\n",
    "\n",
    "DataSet_ALS = ALSDataset(dir_HC, dir_ALS)\n",
    "# print(len(DataSet_ALS))\n",
    "X_generic, y_label = DataSet_ALS.__getitem__(15200)\n",
    "\n",
    "plt.pcolor(X_generic, cmap='jet')\n",
    "print('label = ', y_label)\n",
    "fold_0_train,fold_0_val,fold_0_test = DataSet_ALS.get_kth_fold_inds(0)\n",
    "# print(fold_0_train)\n",
    "# print(fold_0_val)\n",
    "# print(fold_0_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALS_FFNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ALS_FFNN,self).__init__() \n",
    "        # parameters\n",
    "        file = open(\"config.json\")\n",
    "        config = json.load(file)            \n",
    "        self.n_mel = config['data']['n_mel_channels']\n",
    "        self.frames_in_segment = config['data']['supra_frame_length']\n",
    "        self.drop1 = nn.Dropout(p=0.25)\n",
    "        self.fc = nn.Linear(self.n_mel*self.frames_in_segment,1)\n",
    "        nn.init.xavier_uniform_(self.fc.weight, gain=1.0,)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x.view(-1,self.n_mel*self.frames_in_segment)\n",
    "        out = self.drop1(out)\n",
    "        out = self.fc(out)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader):    \n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        model.train()\n",
    "        for specs, labels in train_loader:\n",
    "            specs = specs.float()\n",
    "            outputs = model(specs)\n",
    "            outputs = outputs.squeeze()            \n",
    "            # print(outputs)\n",
    "            # print(labels)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "\n",
    "        if epoch==1 or epoch%5==0:\n",
    "            # prediction on val set        \n",
    "            val_score = list()\n",
    "            loss_val = 0.0\n",
    "            TP_TN_sum = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for spec, label in val_loader:\n",
    "                    spec = spec.float()                    \n",
    "                    pred = model(spec)\n",
    "                    pred = torch.squeeze(pred,1)\n",
    "                    # print(pred)\n",
    "                    # print(label)\n",
    "                    loss = loss_fn(pred, label)\n",
    "                    loss_val += loss.item()\n",
    "                    val_score.append(pred.numpy())\n",
    "                    if pred>0:\n",
    "                        pred = torch.tensor(1, dtype=torch.float64)                        \n",
    "                    else:\n",
    "                        pred = torch.tensor(0, dtype=torch.float64)\n",
    "                    if pred==label:\n",
    "                        TP_TN_sum +=1                                                \n",
    "\n",
    "            print(f'{datetime.datetime.now()} Epoch {epoch}, Train loss {loss_train / len(train_loader):.3f}, Val loss {loss_val / len(val_loader):.3f}, Acc_val = {TP_TN_sum/len(val_score):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single NN training & evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-15 11:30:11.521418 Epoch 1, Train loss 2.361, Val loss 1.688, Acc_val = 0.69\n",
      "2023-05-15 11:30:14.980231 Epoch 5, Train loss 0.783, Val loss 1.099, Acc_val = 0.84\n",
      "2023-05-15 11:30:19.330133 Epoch 10, Train loss 0.463, Val loss 1.488, Acc_val = 0.82\n",
      "2023-05-15 11:30:23.673189 Epoch 15, Train loss 0.375, Val loss 1.035, Acc_val = 0.76\n",
      "2023-05-15 11:30:27.987939 Epoch 20, Train loss 0.254, Val loss 1.912, Acc_val = 0.82\n"
     ]
    }
   ],
   "source": [
    "fold_0_train_inds,fold_0_val_inds,fold_0_test_inds = DataSet_ALS.get_kth_fold_inds(0)\n",
    "train_set = torch.utils.data.dataset.Subset(DataSet_ALS, fold_0_train_inds)\n",
    "val_set = torch.utils.data.dataset.Subset(DataSet_ALS, fold_0_val_inds)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=50, shuffle=True) # num_workers=1\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, shuffle=False) # num_workers=1\n",
    "\n",
    "ALS_ffnn = ALS_FFNN()\n",
    "ALS_ffnn.train()\n",
    "\n",
    "# summary(ALS_cnn,(64*86))\n",
    "# optimizer = optim.SGD(ALS_cnn.parameters(), lr=1e-3, momentum=0.10)\n",
    "optimizer = optim.Adam(ALS_ffnn.parameters(),lr=1e-4)\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# pos_weight = torch.ones([1])\n",
    "# loss_fn = nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs=20,\n",
    "    optimizer=optimizer,\n",
    "    model=ALS_ffnn,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader = val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALS_ffnn.eval()\n",
    "\n",
    "test_set = torch.utils.data.dataset.Subset(DataSet_ALS, fold_0_test_inds)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False) # num_workers=1\n",
    "\n",
    "test_score = list()\n",
    "TP_TN_sum = 0\n",
    "with torch.no_grad():\n",
    "    for spec, label in test_loader:\n",
    "        spec = spec.float()\n",
    "        spec = spec.squeeze()\n",
    "        pred = ALS_ffnn(spec)\n",
    "        test_score.append(pred.numpy())\n",
    "        if pred>0:\n",
    "            pred = torch.tensor(1, dtype=torch.float64)\n",
    "        else:\n",
    "            pred = torch.tensor(0, dtype=torch.float64)\n",
    "            # print('Neg example')    \n",
    "        if pred==label:\n",
    "            TP_TN_sum +=1\n",
    "\n",
    "print('Acc = ', TP_TN_sum/len(test_score))\n",
    "\n",
    "test_score = np.array(test_score).squeeze()\n",
    "plt.plot(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalid(dataset=None, model = None, train = None, k_fold=5):    \n",
    "    \n",
    "    total_size = len(dataset)\n",
    "    y_pred = np.ndarray(total_size)\n",
    "    y_true = np.ndarray(total_size)\n",
    "\n",
    "    for i in range(k_fold):\n",
    "        \n",
    "        inds_train,inds_val,inds_test = dataset.get_kth_fold_inds(i)                \n",
    "        \n",
    "        train_set = torch.utils.data.dataset.Subset(dataset,inds_train)\n",
    "        val_set = torch.utils.data.dataset.Subset(dataset,inds_val)\n",
    "        test_set = torch.utils.data.dataset.Subset(dataset,inds_test)\n",
    "                \n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=50,\n",
    "                                          shuffle=True)  # num_workers=2\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "        test_loader = torch.utils.data.DataLoader(test_set, batch_size=1,\n",
    "                                          shuffle=False)    # num_workers=2\n",
    "        with torch.no_grad():\n",
    "            for layer in model.children():\n",
    "                if hasattr(layer, 'reset_parameters'):\n",
    "                    layer.reset_parameters()\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        # optimizer = optim.SGD(ALS_cnn.parameters(), lr=1e-3, momentum=0.10)\n",
    "        optimizer = optim.Adam(model.parameters(),lr=5e-4, weight_decay=1e-2) # weight_decay is L2 regularization\n",
    "\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        train(\n",
    "            n_epochs=50,\n",
    "            optimizer=optimizer,\n",
    "            model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader\n",
    "        )\n",
    "\n",
    "        # prediction on test set        \n",
    "        test_score = list()\n",
    "        TP_TN_sum = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            i = 0\n",
    "            for spec, label in test_loader:\n",
    "                spec = spec.float()\n",
    "                spec = spec.squeeze()\n",
    "                pred = model(spec)\n",
    "                test_score.append(pred.numpy())\n",
    "                if pred>0:\n",
    "                    pred = torch.tensor(1, dtype=torch.float64)\n",
    "                    y_pred[inds_test[i]] = 1\n",
    "                else:\n",
    "                    pred = torch.tensor(0, dtype=torch.float64)                \n",
    "                    y_pred[inds_test[i]] = 0\n",
    "                y_true[inds_test[i]] = label\n",
    "                if pred==label:\n",
    "                    TP_TN_sum +=1                \n",
    "                i +=1                 \n",
    "            print('Acc = ', TP_TN_sum/len(test_score))\n",
    "\n",
    "    acc_sk = metrics.accuracy_score(y_true, y_pred)\n",
    "    recall = metrics.recall_score(y_true, y_pred)\n",
    "    prec = metrics.precision_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensetivity = tp / (tp+fn)\n",
    "    specificity = tn / (tn+fp)\n",
    "    print('Final results')\n",
    "    print(f'Acc_sk = {acc_sk:.2f}', )\n",
    "    print(f'Prec = {prec:.2f}')\n",
    "    print(f'Recall = {recall:.2f}')\n",
    "    print(f'Sens = {sensetivity:.2f}')\n",
    "    print(f'Spec = {specificity:.2f}')\n",
    "\n",
    "        # val_acc = valid(res_model,criterion,optimizer,val_loader)\n",
    "        # val_score.at[i] = val_acc\n",
    "    \n",
    "    return acc_sk\n",
    "        \n",
    "# https://stackoverflow.com/questions/60883696/k-fold-cross-validation-using-dataloaders-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-15 11:37:05.952400 Epoch 1, Train loss 8.322, Val loss 2.139, Acc_val = 0.80\n",
      "2023-05-15 11:37:10.699350 Epoch 5, Train loss 3.222, Val loss 3.746, Acc_val = 0.80\n",
      "2023-05-15 11:37:16.575785 Epoch 10, Train loss 2.322, Val loss 1.156, Acc_val = 0.86\n",
      "2023-05-15 11:37:22.566754 Epoch 15, Train loss 2.375, Val loss 0.634, Acc_val = 0.88\n",
      "2023-05-15 11:37:28.548136 Epoch 20, Train loss 3.255, Val loss 0.580, Acc_val = 0.89\n",
      "2023-05-15 11:37:34.399271 Epoch 25, Train loss 3.157, Val loss 5.913, Acc_val = 0.56\n",
      "2023-05-15 11:37:40.350666 Epoch 30, Train loss 3.042, Val loss 2.886, Acc_val = 0.81\n",
      "2023-05-15 11:37:46.213019 Epoch 35, Train loss 2.730, Val loss 3.491, Acc_val = 0.80\n",
      "2023-05-15 11:37:52.203663 Epoch 40, Train loss 3.643, Val loss 2.611, Acc_val = 0.62\n",
      "2023-05-15 11:37:57.916501 Epoch 45, Train loss 2.685, Val loss 0.807, Acc_val = 0.90\n",
      "2023-05-15 11:38:03.671135 Epoch 50, Train loss 3.731, Val loss 3.063, Acc_val = 0.82\n",
      "Acc =  0.7653769841269841\n",
      "2023-05-15 11:38:05.916924 Epoch 1, Train loss 7.377, Val loss 3.265, Acc_val = 0.77\n",
      "2023-05-15 11:38:10.807839 Epoch 5, Train loss 2.716, Val loss 2.092, Acc_val = 0.72\n",
      "2023-05-15 11:38:16.791301 Epoch 10, Train loss 1.853, Val loss 1.893, Acc_val = 0.84\n",
      "2023-05-15 11:38:22.817501 Epoch 15, Train loss 2.032, Val loss 6.485, Acc_val = 0.74\n",
      "2023-05-15 11:38:29.176530 Epoch 20, Train loss 2.209, Val loss 6.517, Acc_val = 0.88\n",
      "2023-05-15 11:38:35.416270 Epoch 25, Train loss 2.231, Val loss 5.096, Acc_val = 0.71\n",
      "2023-05-15 11:38:41.626183 Epoch 30, Train loss 1.864, Val loss 5.478, Acc_val = 0.88\n",
      "2023-05-15 11:38:48.001396 Epoch 35, Train loss 2.227, Val loss 5.810, Acc_val = 0.88\n",
      "2023-05-15 11:38:54.347642 Epoch 40, Train loss 2.515, Val loss 6.512, Acc_val = 0.69\n",
      "2023-05-15 11:39:00.654181 Epoch 45, Train loss 2.152, Val loss 5.756, Acc_val = 0.88\n",
      "2023-05-15 11:39:06.990219 Epoch 50, Train loss 2.268, Val loss 13.623, Acc_val = 0.77\n",
      "Acc =  0.7686230248306998\n",
      "2023-05-15 11:39:09.161827 Epoch 1, Train loss 7.095, Val loss 2.201, Acc_val = 0.85\n",
      "2023-05-15 11:39:13.821126 Epoch 5, Train loss 3.018, Val loss 11.185, Acc_val = 0.73\n",
      "2023-05-15 11:39:19.612152 Epoch 10, Train loss 2.651, Val loss 7.921, Acc_val = 0.63\n",
      "2023-05-15 11:39:25.730230 Epoch 15, Train loss 3.192, Val loss 9.965, Acc_val = 0.63\n",
      "2023-05-15 11:39:31.647459 Epoch 20, Train loss 2.206, Val loss 3.961, Acc_val = 0.65\n",
      "2023-05-15 11:39:37.561666 Epoch 25, Train loss 2.737, Val loss 3.715, Acc_val = 0.69\n",
      "2023-05-15 11:39:43.453664 Epoch 30, Train loss 2.347, Val loss 6.386, Acc_val = 0.70\n",
      "2023-05-15 11:39:49.368365 Epoch 35, Train loss 2.458, Val loss 4.454, Acc_val = 0.61\n",
      "2023-05-15 11:39:55.265472 Epoch 40, Train loss 3.350, Val loss 3.872, Acc_val = 0.70\n",
      "2023-05-15 11:40:01.208677 Epoch 45, Train loss 2.706, Val loss 4.195, Acc_val = 0.61\n",
      "2023-05-15 11:40:07.117774 Epoch 50, Train loss 2.745, Val loss 8.040, Acc_val = 0.65\n",
      "Acc =  0.49562615101289137\n",
      "2023-05-15 11:40:09.481021 Epoch 1, Train loss 7.608, Val loss 8.921, Acc_val = 0.69\n",
      "2023-05-15 11:40:14.277639 Epoch 5, Train loss 2.108, Val loss 12.722, Acc_val = 0.44\n",
      "2023-05-15 11:40:20.362100 Epoch 10, Train loss 2.101, Val loss 19.260, Acc_val = 0.64\n",
      "2023-05-15 11:40:26.226299 Epoch 15, Train loss 2.326, Val loss 20.498, Acc_val = 0.53\n",
      "2023-05-15 11:40:32.188470 Epoch 20, Train loss 1.983, Val loss 21.844, Acc_val = 0.62\n",
      "2023-05-15 11:40:38.066197 Epoch 25, Train loss 2.407, Val loss 31.025, Acc_val = 0.63\n",
      "2023-05-15 11:40:43.423863 Epoch 30, Train loss 2.445, Val loss 34.870, Acc_val = 0.58\n",
      "2023-05-15 11:40:48.808504 Epoch 35, Train loss 2.329, Val loss 33.101, Acc_val = 0.69\n",
      "2023-05-15 11:40:54.235111 Epoch 40, Train loss 2.489, Val loss 19.822, Acc_val = 0.42\n",
      "2023-05-15 11:40:59.431430 Epoch 45, Train loss 3.982, Val loss 46.231, Acc_val = 0.43\n",
      "2023-05-15 11:41:04.666900 Epoch 50, Train loss 2.843, Val loss 48.519, Acc_val = 0.38\n",
      "Acc =  0.6806901441739541\n",
      "2023-05-15 11:41:06.915866 Epoch 1, Train loss 7.649, Val loss 4.416, Acc_val = 0.68\n",
      "2023-05-15 11:41:11.212077 Epoch 5, Train loss 3.071, Val loss 7.683, Acc_val = 0.75\n",
      "2023-05-15 11:41:16.377687 Epoch 10, Train loss 2.627, Val loss 8.005, Acc_val = 0.64\n",
      "2023-05-15 11:41:21.618061 Epoch 15, Train loss 2.308, Val loss 6.539, Acc_val = 0.65\n",
      "2023-05-15 11:41:26.882076 Epoch 20, Train loss 2.747, Val loss 9.544, Acc_val = 0.68\n",
      "2023-05-15 11:41:32.095414 Epoch 25, Train loss 2.963, Val loss 9.467, Acc_val = 0.69\n",
      "2023-05-15 11:41:37.610388 Epoch 30, Train loss 2.696, Val loss 14.954, Acc_val = 0.66\n",
      "2023-05-15 11:41:43.129688 Epoch 35, Train loss 2.466, Val loss 15.028, Acc_val = 0.67\n",
      "2023-05-15 11:41:48.569341 Epoch 40, Train loss 2.305, Val loss 8.015, Acc_val = 0.64\n",
      "2023-05-15 11:41:53.822390 Epoch 45, Train loss 3.205, Val loss 9.443, Acc_val = 0.65\n",
      "2023-05-15 11:41:59.114256 Epoch 50, Train loss 2.910, Val loss 8.956, Acc_val = 0.64\n",
      "Acc =  0.842645953395139\n",
      "Final results\n",
      "Acc_sk = 0.70\n",
      "Prec = 0.68\n",
      "Recall = 0.79\n",
      "Sens = 0.79\n",
      "Spec = 0.61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7025506581462668"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_HC = '../wav'+ os.sep + 'HC' + os.sep\n",
    "dir_ALS = '../wav' + os.sep + 'ALS' + os.sep\n",
    "\n",
    "DataSet_ALS = ALSDataset(dir_HC, dir_ALS)\n",
    "ALS_ffnn = ALS_FFNN()\n",
    "\n",
    "crossvalid(dataset=DataSet_ALS, model = ALS_ffnn, train = training_loop, k_fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 86])\n",
      "torch.Size([1, 5504])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Test 1\n",
    "test_img = torch.rand(64,86)\n",
    "test_img_row = test_img.view(-1,64*86)\n",
    "print(test_img.shape)\n",
    "print(test_img_row.shape)\n",
    "\n",
    "# Test 2\n",
    "test_img = torch.rand(1,10)\n",
    "test_img_row = test_img.squeeze()\n",
    "print(test_img.shape)\n",
    "print(test_img_row.shape)\n",
    "\n",
    "#Test 3\n",
    "# print(torch.sigmoid(torch.tensor(-1)), torch.sigmoid(torch.tensor(0)), torch.sigmoid(torch.tensor(1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV-Fold selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26  97 117  85  53  86 127  92 102  27  32  72  39]\n",
      "Fold 1 HC age mean = 52.43, mens = 3, womens = 4\n",
      "Fold 1 ALS age mean = 56.83, mens = 3, womens = 3\n",
      "[ 28 123  63  99  81 125 129  68  21  55  48  78  42]\n",
      "Fold 2 HC age mean = 53.71, mens = 3, womens = 4\n",
      "Fold 2 ALS age mean = 58.33, mens = 4, womens = 2\n",
      "[ 61  16 115 109 111   2 107  46  84  64  52  24  76]\n",
      "Fold 3 HC age mean = 55.43, mens = 2, womens = 5\n",
      "Fold 3 ALS age mean = 59.67, mens = 4, womens = 2\n",
      "[ 77   6  65  24 131 119  25  94  62  28   8  98  22]\n",
      "Fold 4 HC age mean = 53.00, mens = 3, womens = 3\n",
      "Fold 4 ALS age mean = 60.86, mens = 5, womens = 2\n",
      "[ 49  89   4  42 113 121  96  20  58  80  31 100]\n",
      "Fold 5 HC age mean = 54.17, mens = 2, womens = 4\n",
      "Fold 5 ALS age mean = 61.00, mens = 4, womens = 2\n"
     ]
    }
   ],
   "source": [
    "file_name =  'HC_ALS_table.xlsx' # path to file + file name\n",
    "\n",
    "xls_file = pd.ExcelFile(file_name)\n",
    "# print(xls_file.sheet_names)\n",
    "\n",
    "# https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values\n",
    "\n",
    "df_HC = xls_file.parse('Control')\n",
    "df_ALS = xls_file.parse('ALS')\n",
    "# print(df_HC['fold']==1)\n",
    "for fold_num in range(1,6):\n",
    "    HC_fold = df_HC.loc[df_HC['fold']==fold_num]\n",
    "    ALS_fold = df_ALS.loc[df_ALS['fold']==fold_num]\n",
    "    # print(HC_fold)\n",
    "    # print(ALS_fold)\n",
    "    print(np.hstack((HC_fold['Subject code'].to_numpy(), ALS_fold['Subject code'].to_numpy())))\n",
    "    HC_age = (float)(HC_fold.loc[:, 'Age'].mean())\n",
    "    HC_m = (HC_fold.loc[HC_fold['Sex']=='m'])\n",
    "    HC_f = (HC_fold.loc[HC_fold['Sex']=='f'])\n",
    "    ALS_age = (float)(ALS_fold.loc[:, 'Age'].mean())\n",
    "    ALS_m = (ALS_fold.loc[ALS_fold['Sex']=='m'])\n",
    "    ALS_f = (ALS_fold.loc[ALS_fold['Sex']=='f'])\n",
    "    print(f'Fold {fold_num} HC age mean = {HC_age:.2f}, mens = {len(HC_m.index)}, womens = {len(HC_f.index)}')\n",
    "    print(f'Fold {fold_num} ALS age mean = {ALS_age:.2f}, mens = {len(ALS_m.index)}, womens = {len(ALS_f.index)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
